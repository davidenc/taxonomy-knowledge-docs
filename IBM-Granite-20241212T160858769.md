```{=mediawiki}
{{Short description|2023 text-generating language model}}
```
```{=mediawiki}
{{Infobox software
| title = Granite
| logo = IBM granite 2 cubes logo.svg
| developer = [[IBM Research]]<ref name="auto">{{Cite web|url=https://www.forbes.com/sites/stevemcdowell/2023/10/03/ibm-enables-industry-specific-ai-with-granite-foundation-models/|title=IBM's New Granite Foundation Models Enable Safe Enterprise AI|first=Steve|last=McDowell|website=Forbes}}</ref>
| released = {{start date and age|2023|11|7}}
| genre = {{ indented plainlist |
*[[Multimodal learning|Multimodal]]
*[[Large language model]]
*[[Generative pre-trained transformer]]
*[[Foundation model]]
}}
```
\| platform = [IBM Watsonx](IBM_Watsonx "wikilink") (initially)\
[GitHub](GitHub "wikilink")\
[Hugging Face](Hugging_Face "wikilink")\
[RHEL](RHEL "wikilink") AI \| replaces = \| replaced_by = \| license =
[Proprietary](Proprietary_software "wikilink")\
Code models: [Open Source](Open-source_software "wikilink") ([Apache
2.0](Apache_License "wikilink"))[^1] }}
`{{Machine learning|Artificial neural network}}`{=mediawiki} **IBM
Granite** is a series of decoder-only [AI](AI "wikilink") [foundation
models](foundation_model "wikilink") created by [IBM](IBM "wikilink").
It was announced on September 7, 2023,[^2][^3] and an initial paper was
published 4 days later.[^4] Initially intended for use in the IBM\'s
[cloud-based](cloud-based "wikilink") [data](data "wikilink") and
[generative AI](generative_AI "wikilink") platform
[Watsonx](Watsonx "wikilink") along with other models,[^5] IBM opened
the source code of some code models.[^6] Granite models are trained on
datasets curated from [Internet](Internet "wikilink"), [academic
publishings](Academic_publishing "wikilink"),
[code](Source_code "wikilink") datasets,
[legal](Legal_instrument "wikilink") and finance documents.[^7][^8][^9]

## Foundation models {#foundation_models}

A foundation model is an AI model trained on broad data at scale such
that it can be adapted to a wide range of downstream tasks.[^10]

Granite\'s first foundation models were Granite.13b.instruct and
Granite.13b.chat. The \"13b\" in their name comes from 13 billion, the
amount of parameters they have as models, lesser than most of the larger
models of the time. Later models vary from 3 to 34 billion
parameters.[^11][^12]

On May 6, 2024, IBM released the [source code](source_code "wikilink")
of four variations of Granite Code Models under [Apache
2](Apache_License "wikilink"), an open source [permissive
license](Permissive_software_license "wikilink") that allows completely
free use, modification and sharing of the software, and put them on
[Hugging Face](Hugging_Face "wikilink") for public use.[^13][^14]
According to IBM\'s own report, Granite 8b outperforms [Llama
3](Llama_3 "wikilink") on several
[coding](Computer_programming "wikilink") related tasks within similar
range of parameters.[^15][^16]

## See also {#see_also}

-   [Mistral AI](Mistral_AI "wikilink"), a company that also provides
    open source models
-   [GPT](Generative_pre-trained_transformer "wikilink")
-   [LLaMA](LLaMA "wikilink")
-   [Cyc](Cyc "wikilink")
-   [Gemini](Gemini_(language_model) "wikilink")

## References

```{=mediawiki}
{{Reflist}}
```
## External links {#external_links}

-   [GitHub page](https://github.com/ibm-granite)
-   [IBM Granite Playground](https://www.ibm.com/granite/playground/)

```{=mediawiki}
{{IBM}}
```
```{=mediawiki}
{{Artificial intelligence navbox}}
```
[Category:IBM products](Category:IBM_products "wikilink") [Category:IBM
software](Category:IBM_software "wikilink") [Category:Large language
models](Category:Large_language_models "wikilink") [Category:Generative
artificial
intelligence](Category:Generative_artificial_intelligence "wikilink")
[Category:Artificial neural
networks](Category:Artificial_neural_networks "wikilink") [Category:2023
software](Category:2023_software "wikilink") [Category:Free
software](Category:Free_software "wikilink")

[^1]:
    ```{=mediawiki}
    {{Citation |title=ibm-granite/granite-code-models |date=2024-05-08 |url=https://github.com/ibm-granite/granite-code-models |access-date=2024-05-08 |publisher=IBM Granite}}
    ```

[^2]:
    ```{=mediawiki}
    {{Cite web|url=https://www.ibm.com/blog/building-ai-for-business-ibms-granite-foundation-models|title=Building AI for business: IBM's Granite foundation models|first=Dinesh|last=Nirmal|website=[[IBM]] |date=September 7, 2023}}
    ```

[^3]:
    ```{=mediawiki}
    {{Cite web|url=https://siliconangle.com/2023/09/07/ibm-debuts-granite-series-hardware-efficient-language-models/|title=IBM debuts Granite series of hardware-efficient language models|date=September 7, 2023}}
    ```

[^4]:
    ```{=mediawiki}
    {{cite web |title=Granite Foundation Models |url=https://www.ibm.com/downloads/cas/X9W4O6BM |publisher=IBM |format=PDF |date=2023-11-30}}
    ```

[^5]:
    ```{=mediawiki}
    {{Cite web |last=Fritts |first=Harold |date=2024-04-22 |title=IBM Adds Meta Llama 3 To watsonx, Expands AI Offerings |url=https://www.storagereview.com/news/ibm-adds-meta-llama-3-to-watsonx-expands-ai-offerings |access-date=2024-05-08 |website=StorageReview.com |language=en-US}}
    ```

[^6]:
    ```{=mediawiki}
    {{Cite web |last=Jindal |first=Siddharth |date=2024-05-07 |title=IBM Releases Open-Source Granite Code Models, Outperforms Llama 3 |url=https://analyticsindiamag.com/ibm-releases-open-source-granite-code-models-outperforms-llama-3/ |access-date=2024-05-08 |website=Analytics India Magazine |language=en-US}}
    ```

[^7]:
    ```{=mediawiki}
    {{Cite web |last=Azhar |first=Ali |date=2024-04-08 |title=IBM Patents a Faster Method to Train LLMs for Enterprises |url=https://www.datanami.com/2024/04/08/ibm-patents-a-faster-method-to-train-llms-for-enterprises/ |access-date=2024-05-08 |website=Datanami}}
    ```

[^8]:
    ```{=mediawiki}
    {{Cite web |last=Wiggers |first=Kyle |date=2023-09-07 |title=IBM rolls out new generative AI features and models |url=https://techcrunch.com/2023/09/07/ibm-rolls-out-new-generative-ai-features-and-models/ |access-date=2024-05-08 |website=TechCrunch |language=en-US}}
    ```

[^9]:

[^10]:
    ```{=mediawiki}
    {{cite web|url=https://hai.stanford.edu/news/introducing-center-research-foundation-models-crfm|title=Introducing the Center for Research on Foundation Models (CRFM)|website=Stanford HAI|date=18 August 2021 }}
    ```

[^11]:

[^12]:
    ```{=mediawiki}
    {{Cite web |last=Pawar |first=Sahil |date=2023-09-11 |title=IBM Introduces Granite Series LLM Models for Watsonx Platform |url=https://analyticsdrift.com/ibm-introduces-granite-series-llm-models-for-watsonx-platform/ |access-date=2024-05-09 |website=Analytics Drift |language=en-US}}
    ```

[^13]:
    ```{=mediawiki}
    {{Cite news |last=Nine |first=Adrianna |date=May 7, 2024 |title=IBM Makes Granite AI Models Open-Source Under New InstructLab Platform |url=https://www.extremetech.com/computing/ibm-makes-granite-ai-models-open-source-under-new-instructlab-platform |work=[[ExtremeTech]]}}
    ```

[^14]:
    ```{=mediawiki}
    {{Cite web |title=IBM open-sources its Granite AI models - and they mean business |url=https://www.zdnet.com/article/ibm-open-sources-its-granite-ai-models-and-they-mean-business/ |access-date=2024-05-21 |website=ZDNET |language=en}}
    ```

[^15]:
    ```{=mediawiki}
    {{Cite web |last=Jindal |first=Siddharth |date=2024-05-07 |title=IBM Releases Open-Source Granite Code Models, Outperforms Llama 3 |url=https://analyticsindiamag.com/ibm-releases-open-source-granite-code-models-outperforms-llama-3/ |access-date=2024-05-09 |website=Analytics India Magazine |language=en-US}}
    ```

[^16]:
    ```{=mediawiki}
    {{Cite web |last=Synced |date=2024-05-13 |title=IBM's Granite Code: Powering Enterprise Software Development with AI Precision {{!}}
    ```
    Synced
    \|url=<https://syncedreview.com/2024/05/13/ibms-granite-code-powering-enterprise-software-development-with-ai-precision/>
    \|access-date=2024-05-21 \|website=syncedreview.com
    \|language=en-US}}
